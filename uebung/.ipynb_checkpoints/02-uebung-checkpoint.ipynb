{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntax natürlicher Sprachen, WS 2025/26\n",
    "\n",
    "# 02 - Übung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tree import Tree\n",
    "from nltk.parse.generate import generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Aufgabe 1 - Ergänzung um Phrasenkategorien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Ergänzen Sie in folgendem Klammerausdruck (aus der vorherigen Übung) die Phrasenkategorie-Label und generieren Sie den entsprechenden Syntaxbaum, indem Sie die Codezelle anschließend ausführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 S                              \n",
      "      ┌──────────────────────────┴──────────┐                    \n",
      "      │                                     VP                  \n",
      "      │                ┌────────────────────┴───────┐            \n",
      "      │                VP                           PP          \n",
      "      │          ┌─────┴─────────┐              ┌───┴──────┐     \n",
      "      NP         │               NP             │          NP   \n",
      "      │          │               │              │          │     \n",
      "Fischers_Fritz fischt     die_frischen_Fis     aus     dem_Fluss\n",
      "                                che                             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = Tree.fromstring(\"\"\"\n",
    "(S\n",
    "    (NP Fischers_Fritz)\n",
    "    (VP\n",
    "        (VP\n",
    "            fischt\n",
    "            (NP die_frischen_Fische)\n",
    "        )\n",
    "        (PP\n",
    "            aus\n",
    "            (NP dem_Fluss)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Aufgabe 2 - Phrasen und Konstituenten*\n",
    "\n",
    "#### Erläutern Sie am Beispiel des Wortes *Verloren* im folgenden Satz den Unterschied zwischen Konstituente und Phrase.\n",
    "\n",
    "- *Verloren hat er seinen Schlüsselbund zwar noch nie, aber oft genug verlegt.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Aufgabe 3 - Wortarten*\n",
    "\n",
    "### (a) Bestimmen Sie die Wortarten des folgenden Satzes. Geben Sie jeweils das entsprechende Tag aus dem Universal Dependency (http://universaldependencies.org/u/pos/) Tagset an. Sie können für einen Vergleich auch weitere Tagsets verwenden.\n",
    "\n",
    "*Sie gab ihm das neue Buch von Chomsky, aber er zeigte kein Interesse daran.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| *Tagset:* | Sie | gab | ihm | das | neue | Buch | von | Chomsky | aber | er  | zeigte | kein | Interesse | daran |\n",
    "| --- | --- | --- | --- | --- | ---- | ---- | --- | -------- | ---- | --- | ------ | ---- | --------- | ------ |\n",
    "|  | PRON | V | PRON | DET | ADJ  | NOUN  | P | PROPN      | CONJ  | PRON | V    | TAG  | N       | TAG    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Vergleichen Sie ihre Tabelle anschließend mit dem Output des Spacy-Taggers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'de_core_news_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m nlp = \u001b[43mspacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mde_core_news_sm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m doc = nlp(\u001b[33m'\u001b[39m\u001b[33mSie gab ihm das neue Buch von Chomsky, aber er zeigte kein Interesse daran.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/__init__.py:51\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m     28\u001b[39m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m     29\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     34\u001b[39m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] = util.SimpleFrozenDict(),\n\u001b[32m     35\u001b[39m ) -> Language:\n\u001b[32m     36\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m \u001b[33;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m \u001b[33;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/spacy/util.py:472\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E050.format(name=name))\n",
      "\u001b[31mOSError\u001b[39m: [E050] Can't find model 'de_core_news_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "doc = nlp('Sie gab ihm das neue Buch von Chomsky, aber er zeigte kein Interesse daran.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_string = '{:10s} {:10s} {:10s}'\n",
    "print(format_string.format('Text', 'UD Tag', 'TIGER Tag'))\n",
    "print(format_string.format(*(['==========']*3)))\n",
    "for token in doc:\n",
    "    print(format_string.format(token.text, token.pos_, token.tag_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Verwenden Sie Spacy zur Auflösung unklarer Tagnamen.\n",
    "\n",
    "- `spacy.explain()` ist eine Funktion in der Spacy-Bibliothek, die eine textuelle Erklärung für eine gegebene Spacy-Token-ID oder POS-Tag liefert.\n",
    "\n",
    "- Sie können auch `nltk.help.upenn_tagset()` für zusätzliche Beispiele für die POS-Tags der Penn Treebank verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'noun'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Aufgabe 4 - Distributionsanalysen*\n",
    "\n",
    "#### Mit Hilfe  des NLTK können distributionsäquivalente Wörter gesucht werden, also solche, die in gleichen Kontexten auftreten (vgl. https://www.nltk.org/book/ch05.html#using-a-tagger).\n",
    "\n",
    "#### Betrachten Sie folgenden Aufruf und erläutern Sie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "little new first good small large great the old other strong young\n",
      "major white second short beautiful a best long\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())\n",
    "text.similar('big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erläuterung:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Aufgabe 5 - Wortarten im Kontext*\n",
    "\n",
    "#### Betrachten sie folgende Sätze:\n",
    "1. *Er spielt gerne Schach.*\n",
    "2. *Er spielt gut Schach.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diskutieren Sie, ob es sich bei dem Wort *gerne* in Satz 1 um ein Adverb oder ein Adjektiv handelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Um welche Wortart handelt es sich bei dem Lexem *gut* in Satz 2? Diskutieren Sie die Probleme, die hier bei der Wortartenbestimmung auftreten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Welche Wortart könnte man für das Wort gut in Satz 2 vermuten, wenn man Adverbien nicht morphologisch, sondern semantisch charakterisiert (als Wortart, die der Modifizierung des Verbalgeschehens dient)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Aufgabe 6 - Phrasenstrukturbaum\n",
    "\n",
    "#### Geben Sie nun für den Satz aus Aufgabe 1 einen vollständigen Phrasenstrukturbaum inklusive Wortart-Label an:\n",
    "\n",
    "*Fischers Fritz fischt die frischen Fische aus dem Fluss.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              S                       \n",
      "       ┌──────────────────────┴──────┐                 \n",
      "       │                             VP               \n",
      "       │          ┌───────────┬──────┴────────┐        \n",
      "       NP         │           NP              PP      \n",
      "  ┌────┴────┐     │     ┌─────┼──────┐    ┌───┼────┐   \n",
      "PROPN     PROPN   V    DET   ADJ    NOUN  P  DET  NOUN\n",
      "  │         │     │     │     │      │    │   │    │   \n",
      "Fisch     Fritz fischt die frische Fisch aus dem Fluss\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = Tree.fromstring(\"\"\"\n",
    "(S\n",
    "    (NP (PROPN Fisch) (PROPN Fritz))\n",
    "    (VP\n",
    "        (V fischt)\n",
    "        (NP (DET die) (ADJ frische) (NOUN Fisch))\n",
    "        (PP (P aus) (DET dem) (NOUN Fluss))\n",
    "    )\n",
    "\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Aufgabe 7 - Eine erste Phrasenstrukturgrammatik*\n",
    "\n",
    "#### (a) Betrachten Sie folgende einfache kontextfreie Grammatik (CFG) und erklären Sie deren Funktionsweise anhand der in der Vorlesung besprochenen Konzepte von CFGs.\n",
    "\n",
    "#### Gehen Sie dabei besonders auf folgende Konzepte ein:\n",
    "\n",
    "- Non-Terminale vs. Terminale\n",
    "- Regelaufbau von CFGS (LHS vs. RHS usw.)\n",
    "- Startsymbol\n",
    "- syntaktische vs. lexikalische Regeln\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> PROPN\n",
    "    VP -> V NP\n",
    "    PROPN -> \"Maria\" | \"Moritz\"\n",
    "    V -> \"kennt\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erklärung durch Kommentare:\n",
    "    S -> NP VP #\n",
    "    NP -> PROPN\n",
    "    VP -> V NP\n",
    "    PROPN -> \"Maria\" | \"Moritz\"\n",
    "    V -> \"kennt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Parsen Sie den gegebenen Satz mit Hilfe der Grammatik, indem Sie das folgende Python-Skript ausführen. Erläutern Sie die Funktionsweise des Codes durch Kommentare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (PROPN Maria)) (VP (V kennt) (NP (PROPN Moritz))))\n",
      "        S             \n",
      "  ┌─────┴────┐         \n",
      "  │          VP       \n",
      "  │     ┌────┴────┐    \n",
      "  NP    │         NP  \n",
      "  │     │         │    \n",
      "PROPN   V       PROPN \n",
      "  │     │         │    \n",
      "Maria kennt     Moritz\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sent = \"Maria kennt Moritz\"\n",
    "\n",
    "parser = nltk.ChartParser(grammar)\n",
    "for tree in parser.parse(sent.split()):\n",
    "    print(tree)\n",
    "    tree.pretty_print(unicodelines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Überlegen Sie zunächst, wie viele Sätze von dieser Grammatik generiert werden können, bevor Sie den folgenden Codeblock ausführen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in generate(grammar, depth=5):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 8 - Erweiterung Phrasenstrukturgrammatik\n",
    "#### Erweitern Sie die Grammatik aus der vorherigen Aufgabe um syntaktische sowie lexikalische Regeln für eine adverbiale Ergänzung mit *(sehr) gut*.\n",
    "\n",
    "#### Testen Sie dazu mit untenstehenden Beispielsätzen, ob Ihre Grammatik den Satz ableitet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\n",
    "    \"Maria kennt Moritz gut\",\n",
    "    \"Maria kennt Moritz sehr gut\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> PROPN\n",
    "    VP -> V NP\n",
    "    PROPN -> \"Maria\" | \"Moritz\"\n",
    "    V -> \"kennt\"\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar)\n",
    "for sent in sents:\n",
    "    trees = list(parser.parse(sent.split()))\n",
    "    if trees: [tree.pretty_print(unicodelines=True) for tree in trees]\n",
    "    else: print(\"no parse found for: \" + sent) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
